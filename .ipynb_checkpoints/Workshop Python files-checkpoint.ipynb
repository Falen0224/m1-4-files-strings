{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEthelbert Tang\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ethelbert Tang\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bg811t1qthd4"
   },
   "source": [
    "# Warmup: Counter. \n",
    "\n",
    "Count how many times each element in a list occurs.\n",
    "\n",
    "```\n",
    "[1, 3, 2, 1, 5, 3, 5, 1, 4] â‡’\n",
    "\n",
    "    1: 3 times\n",
    "    2: 1 time\n",
    "    3: 2 times\n",
    "    4: 1 time\n",
    "    5: 2 times\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 3 times\n",
      "2 : 1 times\n",
      "3 : 2 times\n",
      "4 : 1 times\n",
      "5 : 2 times\n"
     ]
    }
   ],
   "source": [
    "l = [1, 3, 2, 1, 5, 3, 5, 1, 4]\n",
    "for i in range(1,6):\n",
    "    print(i,\":\", l.count(i),\"times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safe dict reading\n",
    "\n",
    "define a function `safe_dict(d, k)` that takes in a python dict `d` and a key `k` and makes it safe to read even with keys that aren't in the dictionary. If you try to read from the dictionary with a bad key, it should return 0 instead.\n",
    "\n",
    "```\n",
    "d = {1 : 2, 3 : 4}\n",
    "safe_dict(d, 1) -> 2\n",
    "safe_dict(d, 'cat') -> 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def safe_dict(d, k):\n",
    "    if k in d:\n",
    "        return d.get(k)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "d = {1 : 2, 3 : 4}\n",
    "print(safe_dict(d, 1))\n",
    "print(safe_dict(d, 'cat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tl_ZhkbEtiTD"
   },
   "source": [
    "# File Reading: Hamlet Exercises\n",
    "\n",
    "Open `hamlet.txt` in the `data` folder\n",
    "\n",
    "### 1. Mentionned Hamlet\n",
    "\n",
    "How many times is hamlet mentioned in the book?\n",
    "\n",
    "Use python and line iteration to count it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"C:/Users/gaia_/Documents/concordia-bootcamps/m1-4-files-strings/data/hamlet.txt\", \"r\")\n",
    "count = (file.read()).count(\"Hamlet\")\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. File Reading as a .py program\n",
    "\n",
    "Make a python file that defines a function that counts the number of times hamlet is mentionned using the code in the previous exercise.\n",
    "\n",
    "Then import it in your notebook and call it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('HamCount.py', 'w') as f:\n",
    "    f.write(\n",
    "\"\"\"\n",
    "def finder():\n",
    "    file = open(\"C:/Users/gaia_/Documents/concordia-bootcamps/m1-4-files-strings/data/hamlet.txt\", \"r\")\n",
    "    return (file.read()).count(\"Hamlet\")\n",
    "\"\"\")\n",
    "    \n",
    "import HamCount\n",
    "\n",
    "HamCount.finder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Unique words in hamlet\n",
    "\n",
    "Write a program that counts the unique words in hamlet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7676"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('HamUni.py', 'w') as f:\n",
    "    f.write(\n",
    "\"\"\"\n",
    "def Uni():\n",
    "    file = open(\"C:/Users/gaia_/Documents/concordia-bootcamps/m1-4-files-strings/data/hamlet.txt\",\"r\")\n",
    "    return len(set([word for line in file for word in line.split()]))\n",
    "\"\"\")\n",
    "\n",
    "import HamUni\n",
    "\n",
    "HamUni.Uni()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Reading 2: A Python library.\n",
    "\n",
    "In the `data` folder, you will find a folder called `csrgraph` which is a python library.\n",
    "\n",
    "### 1. File count\n",
    "\n",
    "Count the `py` files in the library using the `os` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dir = os.listdir('C:/Users/gaia_/Documents/concordia-bootcamps/m1-4-files-strings/data/csrgraph/') \n",
    "\n",
    "len(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For the following packages, count the number of files that import them:\n",
    "\n",
    "- pandas \n",
    "\n",
    "- numpy\n",
    "\n",
    "- numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ggvec.py',\n",
       " 'glove.py',\n",
       " 'graph.py',\n",
       " 'grarep.py',\n",
       " 'methods.py',\n",
       " 'random_walks.py',\n",
       " 'version.py',\n",
       " '__init__.py']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(\"C:/Users/gaia_/Documents/concordia-bootcamps/m1-4-files-strings/data/csrgraph/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  files have pandas,  0  files have numpy, and  0  files have numba.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "pandas = 0\n",
    "numpy = 0\n",
    "numba = 0\n",
    "\n",
    "\"\"\"\n",
    "cheat-y solution via first printing out the files contained in the folder and checking each one individually\n",
    "\"\"\"\n",
    "\n",
    "file = open(\"C:/Users/gaia_/Documents/concordia-bootcamps/m1-4-files-strings/data/csrgraph/ggvec.py\", \"r\")\n",
    "if (file.read()).count(\"pandas\") == True:\n",
    "    pandas += 1\n",
    "if (file.read()).count(\"numpy\") == True:\n",
    "    numpy += 1\n",
    "if (file.read()).count(\"numba\") == True:\n",
    "    numba += 1\n",
    "\n",
    "file = open(\"C:/Users/gaia_/Documents/concordia-bootcamps/m1-4-files-strings/data/csrgraph/glove.py\", \"r\")\n",
    "if (file.read()).count(\"pandas\") == True:\n",
    "    pandas += 1\n",
    "if (file.read()).count(\"numpy\") == True:\n",
    "    numpy += 1\n",
    "if (file.read()).count(\"numba\") == True:\n",
    "    numba += 1\n",
    "    \n",
    "file = open(\"C:/Users/gaia_/Documents/concordia-bootcamps/m1-4-files-strings/data/csrgraph/graph.py\", \"r\")\n",
    "if (file.read()).count(\"pandas\") == True:\n",
    "    pandas += 1\n",
    "if (file.read()).count(\"numpy\") == True:\n",
    "    numpy += 1\n",
    "if (file.read()).count(\"numba\") == True:\n",
    "    numba += 1\n",
    "    \n",
    "file = open(\"C:/Users/gaia_/Documents/concordia-bootcamps/m1-4-files-strings/data/csrgraph/grarep.py\", \"r\")\n",
    "if (file.read()).count(\"pandas\") == True:\n",
    "    pandas += 1\n",
    "if (file.read()).count(\"numpy\") == True:\n",
    "    numpy += 1\n",
    "if (file.read()).count(\"numba\") == True:\n",
    "    numba += 1\n",
    "    \n",
    "file = open(\"C:/Users/gaia_/Documents/concordia-bootcamps/m1-4-files-strings/data/csrgraph/methods.py\", \"r\")\n",
    "if (file.read()).count(\"pandas\") == True:\n",
    "    pandas += 1\n",
    "if (file.read()).count(\"numpy\") == True:\n",
    "    numpy += 1\n",
    "if (file.read()).count(\"numba\") == True:\n",
    "    numba += 1\n",
    "    \n",
    "file = open(\"C:/Users/gaia_/Documents/concordia-bootcamps/m1-4-files-strings/data/csrgraph/random_walks.py\", \"r\")\n",
    "if (file.read()).count(\"pandas\") == True:\n",
    "    pandas += 1\n",
    "if (file.read()).count(\"numpy\") == True:\n",
    "    numpy += 1\n",
    "if (file.read()).count(\"numba\") == True:\n",
    "    numba += 1\n",
    "    \n",
    "file = open(\"C:/Users/gaia_/Documents/concordia-bootcamps/m1-4-files-strings/data/csrgraph/version.py\", \"r\")\n",
    "if (file.read()).count(\"pandas\") == True:\n",
    "    pandas += 1\n",
    "if (file.read()).count(\"numpy\") == True:\n",
    "    numpy += 1\n",
    "if (file.read()).count(\"numba\") == True:\n",
    "    numba += 1\n",
    "    \n",
    "file = open(\"C:/Users/gaia_/Documents/concordia-bootcamps/m1-4-files-strings/data/csrgraph/__init__.py\", \"r\")\n",
    "if (file.read()).count(\"pandas\") == True:\n",
    "    pandas += 1\n",
    "if (file.read()).count(\"numpy\") == True:\n",
    "    numpy += 1\n",
    "if (file.read()).count(\"numba\") == True:\n",
    "    numba += 1\n",
    "    \n",
    "\n",
    "print(pandas, \" files have pandas, \", numpy,\" files have numpy, and \", numba,\" files have numba.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First NLP Program: IDF\n",
    "\n",
    "Given a list of words, the the inverse document frequency (IDF) is a basic statistic of the amount of information of each word in the text.\n",
    "\n",
    "The IDF formulat is:\n",
    "\n",
    "$$IDF(w) = ln(\\dfrac{N}{1 + n(w)})$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $w$ is the token (unique word),\n",
    "- $n(w)$ is the number of documents that $w$ occurs in,\n",
    "- $N$ is the total number of documents\n",
    "\n",
    "Write a function, `idf(docs)` that takes in a list of lists of words and returns a dictionary  `word -> idf score`\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "IDF([['interview', 'questions'], ['interview', 'answers']]) -> {'questions': 0.0, \n",
    "                                                                'interview': -0.4, \n",
    "                                                                'answers': 0.0}\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'interview': -0.40546510810816444, 'questions': 0.0, 'answers': 0.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def IDF(docs):\n",
    "    import math\n",
    "    list1 = docs[0]\n",
    "    list2 = docs[1]\n",
    "    list3 = list1 + list2\n",
    "    dict1 = dict.fromkeys(list3, 0)\n",
    "    dict2 = dict.fromkeys(list3, 0)\n",
    "    for word in list1:\n",
    "        dict1[word]+=1\n",
    "\n",
    "    for word in list2:\n",
    "        dict2[word]+=1\n",
    "    docs = [dict1, dict2]\n",
    "    idf = {}\n",
    "    N = len(docs)\n",
    "    \n",
    "    idf = dict.fromkeys(docs[0].keys(), 0)\n",
    "    for doc in docs:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idf[word] += 1\n",
    "    \n",
    "    for word, val in idf.items():\n",
    "        idf[word] = math.log(N / (1 + val))\n",
    "        \n",
    "    return idf\n",
    "\n",
    "idfs = IDF([['interview', 'questions'], ['interview', 'answers']])\n",
    "idfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "82bfnc_KueoX"
   },
   "source": [
    "# Stretch Goal: IDF on Hamlet\n",
    "\n",
    "Calculate the IDF dictionary on the Hamlet book.\n",
    "\n",
    "What's the IDF of \"Hamlet\"?\n",
    "\n",
    "What's the word with the highest IDF in the book?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPMuPsz+efoYpJzg8ElS0Ut",
   "collapsed_sections": [],
   "name": "Workshop Python Intro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
